{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "{{{abstract}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multivariable optimization with constraints\n",
    "\n",
    "\n",
    "### Formulation\n",
    "\n",
    "So far we have been looking at various optimization problems, but only\n",
    "of very specific types.  Optimization is clearly important and so we’d\n",
    "like to generalize it some way, so we can tackle more problems.\n",
    "\n",
    "Let’s describe what is more-or-less the most general form of an\n",
    "optimization problem:\n",
    "\n",
    "Consider an \\\\(\\mathbf{R}\\\\)-valued function \\\\(f\\\\) defined for\n",
    "\\\\(\\mathbf{x} \\in \\mathbf{R}^n\\\\) -- thus, \\\\(f:\\mathbf{R}^n \\to\n",
    "\\mathbf{R}\\\\).  We want to optimize \\\\(f(\\mathbf{x})\\\\) subject to a\n",
    "system of *constraints* defined by some auxiliary data.\n",
    "\n",
    "We first consider \\\\(E\\\\) constraints defined for \\\\(1 \\le i \\le E\\\\)\n",
    "by functions \\\\(g_i:\\mathbf{R}^n \\to \\mathbf{R}\\\\) together with values\n",
    "\\\\(b_i \\in \\mathbf{R}\\\\); these constraints\n",
    "have the form \\\\[(\\heartsuit)_i \\quad g_i(\\mathbf{x}) \\le b_i \\\\]\n",
    "\n",
    "At the same time, we consider \\\\(F\\\\) constraints defined for \\\\(1 \\le\n",
    "j \\le F\\\\) by functions \\\\(h_j:\\mathbf{R}^n \\to \\mathbf{R}\\\\) together\n",
    "with values \\\\(c_j \\in \\mathbf{R}\\\\); these constraints have the form\n",
    "\\\\[ (\\clubsuit)_j \\quad h_j(\\mathbf{x}) = c_j \\\\]\n",
    "\n",
    "Re-capping, the problem is to find the optimal value of \\\\(f(\\mathbf{x})\\\\) where\n",
    "\\\\(\\mathbf{x}\\\\) ranges over all points in \\\\(\\mathbf{R}^n\\\\) satisfying\n",
    "the constraints \\\\((\\heartsuit)_i\\\\) and all constraints \\\\((\\clubsuit)_j\\\\).\n",
    " \n",
    "---\n",
    "Compactly, a *general optimization problem* asks to find the maximum (or minimum) of \\\\(f:\\mathbf{R}^n \\to \\mathbf{R}\\\\) for \\\\(\\mathbf{x} \\in \\mathbf{R}^n\\\\) subject to\n",
    "constraints\n",
    "\\\\[\\begin{aligned} g_i(\\mathbf{x}) & \\le b_i & 1 \\le i \\le E \\\\\n",
    "                   h_j(\\mathbf{x}) & = c_j & 1 \\le j \\le F\n",
    "   \\end{aligned} \\\\]\n",
    "For functions \\\\(g_i,h_j:\\mathbf{R}^n \\to \\mathbf{R}\\\\) and scalars \\\\(b_i,c_j\\\\).\n",
    "\n",
    "---\n",
    "- **Remark**: One might wonder why we don't consider constraints of the form\n",
    "\\\\[\\ell(\\mathbf{x}) < d \\\\]\n",
    "or \n",
    "\\\\[\\ell(\\mathbf{x}) \\ge d \\\\]. The answer is that the conditions imposed by constraints\n",
    "of this form can be imposed through (possibly more) constraints of the form \\\\((\\heartsuit)_i\\\\) or \\\\((\\clubsuit)_j\\\\).\n",
    "\n",
    "---\n",
    "\n",
    "## Our older examples all have this form\n",
    "- **single-variable optimization**\n",
    "    \n",
    "    Here we consider the case \\\\(k =1\\\\). Typically we optimize on an interval -- for\n",
    "    example we might want to optimize \\\\(f\\\\) for \\\\(x\\\\) in the closed interval\n",
    "    \\\\([a,b]\\\\). Then one of the constraints has the form \\\\(x \\le b\\\\) (so take \\\\(g_i\\\\))\n",
    "\n",
    "\n",
    "## A \"linear\" example\n",
    "\n",
    "*This example is an instance of a problem in \"linear programming\", as we'll describe below.*\n",
    "\n",
    "> A carpenter can choose to make either tables or bookshelves. She makes a profit of \\\\$25 per constructed table and \\\\$30 per constructed bookshelf (demand is sufficient that all constructed products will be sold). \n",
    "\n",
    "> It takes 5 hours of labor and 20 board-feet of lumber to make a table and 4 hours of labor and 30 board-feet of lumber to make a bookshelf. If she has access to 120 hours of labor and 690 board-feet of lumber each week, how many tables and how many bookshelves should she make to maximize profit? \n",
    "\n",
    "What are the variables?\n",
    "- \\\\(t\\\\) = # of tables made per week\n",
    "- \\\\(b\\\\) = # of bookshelves made per week\n",
    "- \\\\(p\\\\) = profit per week\n",
    "- \\\\(L\\\\) = hours of labor per week\n",
    "- \\\\(W\\\\) = board-feet of lumber used per week\n",
    "\n",
    "What do we know?\n",
    "- \\\\(p = 25t + 30b\\\\)\n",
    "- \\\\(L = 5t + 4b\\\\)\n",
    "- \\\\(W = 20t + 30b\\\\)\n",
    "\n",
    "So the **goal** is to maximize \\\\(p(t, b) = 25t + 30b\\\\), subject to the constraints\n",
    "\\\\[(\\heartsuit) \\quad \\left \\{ . \\begin{matrix*}[l] \n",
    "L(t,b) = 5t + 4b &  \\le 120 \\\\\n",
    "W(t,b) = 20t + 30b & \\le 690  \\\\\n",
    "t & \\ge 0 \\\\\n",
    "b & \\ge 0 \\\\\n",
    "\\end{matrix*} \\right.\\\\]\n",
    "\n",
    "It would be useful to have a schematic showing the region of the plane consting of those points \\\\((t,b)\\\\) which satisfy the constraint \\\\((\\heartsuit)\\\\). This set of points is known as the **feasible set**\n",
    "or **feasible region**.\n",
    "\n",
    "```python\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams.update({'font.size': 19})\n",
    "\n",
    "# plot the feasible region\n",
    "d = np.linspace(-2,30,500)\n",
    "t,b = np.meshgrid(d,d)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(15,15))\n",
    "ax.imshow( ((t>=0) & (b>=0) & (5*t + 4*b <= 120) & (20*t + 30*b <= 690)).astype(int),\n",
    "extent=(t.min(),t.max(),b.min(),b.max()),origin=\"lower\", cmap=\"Reds\", alpha = 0.2)\n",
    "\n",
    "# plot the lines defining the constraints\n",
    "t = np.linspace(-2,30,500)\n",
    "\n",
    "ax.plot(t, (120 - 5*t)/4, label=\"5t+4b = 120\")\n",
    "ax.plot(t, (690 - 20*t)/30, label = \"20t + 30b = 690\")\n",
    "ax.axhline(y=0, color = \"black\")\n",
    "ax.axvline(x=0, color = \"black\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"Carpenter - Feasible Region\")\n",
    "ax.set_xlabel(\"t = #tables\")\n",
    "ax.set_ylabel(\"b = #bookcases\")\n",
    "\n",
    "def ann_pt(x,y):\n",
    "    s = f\"({x},{y})\"\n",
    "    ax.annotate(s,xy=(x,y),xytext=(5,5),textcoords='offset points')\n",
    "\n",
    "ax.scatter(0, 23,s=100,color=\"blue\")\n",
    "ax.scatter(12,15,s=100,color=\"blue\")\n",
    "ax.scatter(24, 0,s=100,color=\"blue\")\n",
    "ax.scatter(0,  0,s=100,color=\"blue\")\n",
    "ann_pt(0,23)\n",
    "ann_pt(12,15)\n",
    "ann_pt(24,0)\n",
    "ann_pt(0,0)\n",
    "\n",
    "```\n",
    "\n",
    "The shaded region is the *feasible region* defined by the constraints \\\\((\\heartsuit)\\\\) above. This region is bounded by (parts of) the graphs of the 4 linear equations: \\\\[b=0, \\quad t=0, \\quad 5t+4b=120, \\quad 20t + 30b = 690.\\\\]\n",
    "\n",
    "We've indicated the points of intersection of these lines.\n",
    "\n",
    "Recall that we are trying to maximize the profit function \\\\(p(t,b)=25 t+30b\\\\)\n",
    "for points in this feasible region. Notice\n",
    "that \n",
    "\\\\[\\dfrac{\\partial p}{\\partial t} = 25 \\quad \\text{and} \\quad \n",
    "\\dfrac{\\partial p}{\\partial b} = 30,\\\\]\n",
    "so the profit function *has no critical points at all*. So the maximum will occur\n",
    "on the **boundary** of the feasible region.\n",
    "\n",
    "But the boundary itself is made up of line segments. And on each line segment, the restriction of \\\\(p\\\\) is again a linear function. For example, on the line \n",
    "\\\\(5t+4b=120\\\\), the profit is given as a function of \\\\(t\\\\) by\n",
    "\\\\[p_1(t) = p(t,b(t)) = p\\left(t,\\dfrac{120-5t}{4}\\right) = 25 t + \\dfrac{30}{4}(120-5t).\\\\]\n",
    "Since \\\\(\\dfrac{p_1}{dt} = \\dfrac{-50}{4}\\\\), again \\\\(p_1\\\\) has no critical points; its max on the boundary line segment will occur at one of the endpoints.\n",
    "\n",
    "In this manner, we see that *the maximum value of \\\\(p\\\\) must occur at one of the itersection points* of boundary lines defining the feasible region, i.e. at one of the points\n",
    "\\\\[(0,0), \\quad (0,23), \\quad (24,0), \\quad \\text{or} \\quad (12,15).\\\\]\n",
    "We find:\n",
    "\\\\[p(0, 0) = 0, \\quad p(24, 0) = 600, \\quad p(0, 23) = 690, \\quad p(12, 15) = 750\\\\]\n",
    "So her profit is maximized by producing 12 tables and 15 bookshelves.\n",
    "\n",
    "\n",
    "## Linear Programming\n",
    "\n",
    "The term *linear programming* refers to optimization problems in which\n",
    "the function to be optimized, as well as all of the constraint equations, are *linear* functions of the variables.\n",
    "\n",
    "The strategy used to find the optimal value in the carepentry example was pretty good! It works well if we only have a few constraints and a few variables. But if we have **many variables and many constraints**, we find **a lot** of vertices in high dimensions. \n",
    "\n",
    "For example, let’s assume given a linear function of 50 variables, and 150 linear constraints (including the conditions that all 50 variables are non-negative). With 50 variables, we expect a point to be specified by exactly 50 linear equations. So we expect a point of intersection of our boundary equations to be determined by selecting 50 of the 150 possible equations. The number of possible ways of choosing 50 items from 150 possible items is the [binomial coefficient](https://en.wikipedia.org/wiki/Binomial_coefficient)  \\\\(\\dbinom{150}{50}\\\\) (read this symbols as \"150 choose 50\"). So the number of intersection points is approximately:\n",
    "\\\\[\\dbinom{150}{50} = \\dfrac{150!}{100!\\cdot 50!} \\approx 2 \\times 10^{40}\\\\]\n",
    "(where \\\\(n!\\\\) means \"\\\\(n\\\\) factorial\").\n",
    "\n",
    "\n",
    "```python\n",
    "import math\n",
    "def binom(n,m):\n",
    "    return math.factorial(n)/(math.factorial(m)*math.factorial(n-m))*1e0\n",
    "    \n",
    "binom(150,100)\n",
    "```\n",
    "\n",
    "<!-- #region -->\n",
    "> Notice that in our carepentry example, there are two variables, and the boundary is defined by 4 equations. Our estimate predicts \\\\(\\dbinom{4}{2} = 6\\\\) intersection points, but of course only 4 of these points are actually on the boundary. You can see the location of the \"extra\" two points in the image above -- on the coordinate axes. Nevertheless, for large numbers of variables and equations, \\\\(\\dbinom{n}{m}\\\\) is a  decent estimate for the number of relevant intersection points.\n",
    "\n",
    "\n",
    "There are roughly \\\\(3 \\times 10^7\\\\) seconds in a year, so\n",
    "a computer that can evaluate the function at a pair \\\\((t,b)\\\\) at a rate of once per nanosecond (\\\\(10^{-9}\\\\) seconds) would take \n",
    "\n",
    "\\\\begin{aligned}\n",
    "\\approx & \\left(2 \\times 10^{40} \\text{operations} \\right)\\cdot \\left (10^{-9} \\dfrac{\\text{seconds}}{\\text{operation}} \\right)\\cdot \\left(\\dfrac{1}{3 \\times 10^7} \\dfrac{\\text{years}}{\\text{second}}\\right)&  \\\\ = & \\left( \\dfrac{2}{3} \\times 10^{24} \\right) =\n",
    "6.\\overline{66} \\times 10^{23} \\quad \\text{years} &\n",
    "\\end{aligned}\n",
    "-- i.e. more than \\\\(6 × 10^{23}\\\\) years to complete the task.\n",
    "\n",
    "Rather than wait so long, we are going to study an algorithm that permits us to ignore some of the vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming -- some preliminaries\n",
    "\n",
    "Let's take a moment and describe linear programming problems using notation from *linear algebra*.\n",
    "If there are \\\\(n\\\\) variables \\\\(x_i\\\\), we write\n",
    "\\\\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbf{R}^n\\\\)\n",
    "for the corresponding \"variable vector\".\n",
    "\n",
    "More generally, we denote by \\\\(\\mathbf{R}^{m \\times n}\\\\) the space of \\\\(m \\times n\\\\) matrices -- i.e. matrices with \\\\(m\\\\) rows and \\\\(n\\\\) columns; thus\n",
    "\\\\[\\mathbf{R}^{m \\times n} = \\left \\{ \n",
    "    \\begin{pmatrix} \n",
    "      a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "      a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n",
    "    \\end{pmatrix} \\ \\bigg \\vert\\ a_{ij} \\in \\mathbf{R} \\right \\} \\\\]\n",
    "\n",
    "Now, a linear function \\\\(\\mathbf{R}^n \\to \\mathbf{R}\\\\) is given by a \\\\(1 \\times n\\\\) matrix -- i.e. a row vector\n",
    "\\\\[\\mathbf{c} = \\begin{bmatrix} c_1 & c_2 & \\cdots & c_n\\end{bmatrix} \\in \\mathbf{R}^{1 \\times n}.\\\\]\n",
    "\n",
    "We will usually reserve the symbol \\\\(\\mathbf{R}^n\\\\) to indicate the space \\\\(\\mathbf{R}^{n \\times 1}\\\\) of **column vectors**; of course, we can view the row vector \\\\(\\mathbf{c}\\\\) as the **transpose** of a column vector, if convenient.\n",
    "\n",
    "The value of the linear function \\\\(\\mathbf{R}^n \\to \\mathbf{R}\\\\) determined by \\\\(\\mathbf{c}\\\\) is given for \\\\(\\mathbf{x} \\in \\mathbf{R}^n\\\\) by the rule \\\\[\\mathbf{x} \\mapsto \\mathbf{c} \\cdot \\mathbf{x} = \\sum_{i=1}^n c_i x_i\\\\] where \\\\(\\mathbf{c} \\cdot \\mathbf{x}\\\\) denotes the *matrix product* (which looks suspiciously like the *dot product*, of course).\n",
    "\n",
    "Now, for a general optimization problem, there are inequality constraints, and equality constraints. \n",
    "- all of these constraints will be given by linear functions, which are determined (as above) by column vectors in \\\\(\\mathbf{R}^n\\\\).\n",
    "- In the setting of linear programming, we only consider *inequality constraints*.The discussion below explains why *equality constraints* aren't needed in linear programming.\n",
    "\n",
    "---\n",
    "\n",
    "Suppose now that the inequality constraints are given by\n",
    "vectors \\\\[\\mathbf{a}_1 = \\begin{bmatrix} a_{1,1} & a_{2,1} & \\cdots & a_{r,1} \\end{bmatrix}, \\mathbf{a}_2,\\cdots,\\mathbf{a}_r \\in \\mathbf{R}^{1 \\times n}\\\\] and scalars \\\\(b_i\\\\) for \\\\(1 \\le i \\le r\\\\).\n",
    "\n",
    "The \\\\(i\\\\)-th inequality constraint requires that\n",
    "\\\\[\\mathbf{a}_i \\cdot \\mathbf{x} \\le b_i\\\\].\n",
    "\n",
    "Now form the \\\\(r \\times n\\\\) matrix \\\\(A\\\\) whose rows are the \\\\(\\mathbf{a}_i\\\\):\n",
    "\\\\[A = \\begin{pmatrix} \\mathbf{a}_1 \\\\ \\mathbf{a}_2 \\\\ \\vdots \\\\ \\mathbf{a}_r\\end{pmatrix}\\\\]\n",
    "The produc \\\\(A \\cdot \\mathbf{x} \\in \\mathbf{R}^r\\\\) is given by \n",
    "\\\\[A \\cdot \\mathbf{x} = \\begin{pmatrix} \\mathbf{a}_1 \\\\ \\mathbf{a}_2 \\\\ \\vdots \\\\ \\mathbf{a}_r \\end{pmatrix}\\cdot \\mathbf{x}\n",
    "= \\begin{pmatrix} \\mathbf{a}_1 \\cdot \\mathbf{x} \\\\ \\mathbf{a}_2 \\cdot \\mathbf{x} \\\\ \\vdots \\\\ \\mathbf{a}_r \\cdot \\mathbf{x} \\end{pmatrix} \\\\]\n",
    "\n",
    "For any \\\\(m \\ge 1\\\\), we declare that two vectors \\\\(\\mathbf{y}\\\\) and \\\\(\\mathbf{z}\\\\) of \\\\(\\mathbf{R}^m\\\\) satisfy \\\\(\\mathbf{y} \\le \\mathbf{z}\\\\) if and only if \\\\(y_i \\le z_i\\\\) for each \\\\(1 \\le i \\le m\\\\). With this convention, the inequality constraints determined by the \\\\(\\mathbf{a}_i\\\\) and \\\\(b_i\\\\) can be written:\n",
    "\\\\[A \\cdot \\mathbf{x} \\le \\mathbf{b}  = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_r\\end{bmatrix}.\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Form\n",
    "\n",
    "Recipulating, a **linear programming problem** is determined by the number \\\\(n\\\\) of variables, the choice of a vector \\\\(\\mathbf{c}, \\mathbf{a}_1, \\mathbf{a}_2,\\cdots,\\mathbf{a}_r \\in \\mathbf{R}^{1 \\times n}\\\\) and the choice of scalars \\\\(b_1,\\dots,b_r\\\\).\n",
    "\n",
    "The goal is to maximize \\\\(\\mathbf{c} \\cdot \\mathbf{x}\\\\) subject to the constraint\n",
    "\\\\[\\mathbf{A} \\cdot \\mathbf{x} \\le \\mathbf{b}\\\\]\n",
    "where \\\\(A = \\begin{pmatrix} \\mathbf{a}_1 \\\\ \\mathbf{a}_2 \\\\ \\vdots \\\\ \\mathbf{a}_r \\end{pmatrix}\\\\) is the \\\\(r \\times n\\\\) matrix whose rows are the row-vectors \\\\(\\mathbf{a}_i\\\\) and \\\\(\\mathbf{b} \\in \\mathbf{R}^r\\\\) has entries \\\\(b_i\\\\).\n",
    "\n",
    "We say that the linear programming problem is posed in standard form if it has this form.\n",
    "\n",
    "* **Remark**: if \\\\(\\mathbf{a} \\in \\mathbf{R}^{1 \\times n}\\\\) and \\\\(b \\in \\mathbf{R}\\\\), an inequality constraint of the form \n",
    "\\\\[(\\clubsuit) \\quad \\mathbf{a} \\cdot \\mathbf{x} \\ge b\\\\]\n",
    "can be rewritten in \"standard form\" by taking \\\\(\\mathbf{\\widetilde a} = -\\mathbf{a}\\\\) and \\\\(\\widetilde b = -b\\\\); then \\\\((\\clubsuit)\\\\) is equivalent to\n",
    "\\\\[\\mathbf{\\widetilde a} \\cdot \\mathbf{x} \\le \\widetilde b\\\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we impose no equality constraints??\n",
    "\n",
    "Consider a *linear programming problem* as above, but suppose also that we imposed  *equality constraints* determined by vectors \\\\[\\mathbf{b}_1 ,\\mathbf{b}_2,\\cdots,\\mathbf{b}_s\\\\]\n",
    "in \\\\(\\mathbf{R}^{1 \\times n}\\\\) and the scalar values \\\\[\\gamma_1,\\gamma_2,\\cdots,\\gamma_s\\\\]\n",
    "\n",
    "In other words, the \\\\(i\\\\)th equality constraint requires that\n",
    "\\\\[(\\clubsuit) \\quad \\mathbf{b}_i \\cdot \\mathbf{x} = \\gamma_i \\\\]\n",
    "Now form the \\\\(s \\times n\\\\) matrix \\\\(B\\\\) whose rows are the \\\\(\\mathbf{b}_i\\\\):\n",
    "\\\\[B = \\begin{pmatrix} \\mathbf{b}_1 \\\\ \\mathbf{b}_2 \\\\ \\vdots \\\\ \\mathbf{b}_s \\end{pmatrix}\\\\]\n",
    "The product \\\\(B \\cdot \\mathbf{x} \\in \\mathbf{R}^s \\\\) is given by \n",
    "\\\\[B \\cdot \\mathbf{x} = \\begin{pmatrix} \\mathbf{b}_1 \\\\ \\mathbf{b}_2 \\\\ \\vdots \\\\ \\mathbf{b}_s \\end{pmatrix}\\cdot \\mathbf{x}\n",
    "= \\begin{pmatrix} \\mathbf{b}_1 \\cdot \\mathbf{x} \\\\ \\mathbf{b}_2 \\cdot \\mathbf{x} \\\\ \\vdots \\\\ \\mathbf{b}_s \\cdot \\mathbf{x} \\end{pmatrix} \\\\]\n",
    "Now, the equality constraints amount to the condition that \\\\[(\\heartsuit) \\quad B \\cdot \\mathbf{x} = \\begin{pmatrix} \\gamma_1 \\\\ \\gamma_2 \\\\ \\vdots \\\\ \\gamma_2 \\end{pmatrix}\\\\].\n",
    "\n",
    "An important observation of *linear algebra* is that the solution set to \\\\((\\heartsuit)\\\\) has the form \\\\[\\mathbf{x}_0 + \\operatorname{Null}(B)\\\\]\n",
    "where \\\\(\\mathbf{x}_0\\\\) is any *particular solution* to \\\\((\\heartsuit)\\\\) and where\n",
    "\\\\(\\operatorname{Null}(B)\\\\) is the *null space* of \\\\(B\\\\) -- \n",
    "\\\\[\\operatorname{Null}(B) = \\left \\{\\mathbf{z} \\in \\mathbf{R}^n \\mid B \\cdot \\mathbf{z} = \\mathbf{0}\\right\\}.\\\\]\n",
    "\n",
    "Now, \\\\(W=\\operatorname{Null}(B)\\\\) is a *linear subspace* of \\\\(\\mathbf{R}^n\\\\). Let \\\\(k = \\dim W \\le n\\\\) be the *dimension* of this null space. If we choose a basis for \\\\(W\\\\), we can identify this space with \\\\(\\mathbf{R}^k\\\\). In case \\\\((\\heartsuit)\\\\) has a solution \\\\(\\mathbf{x}_0\\\\) at all, the set \\\\(\\mathbf{x}_0 + \\operatorname{Null}(B) = \\mathbf{x}_0 + W\\\\) can similarly be identified with \\\\(\\mathbf{R}^k\\\\) (just translate the origin!).\n",
    "\n",
    "* The upshot of all this is that *we don't consider equality constraints in linear programming problems, because imposing equality constraints really amounts to reducing the number of variables of the problem* (from \\\\(n\\\\) to \\\\(k\\\\)). \n",
    "* It is of course quite reasonable to impose equality constraints. Such a linear programming problem is not in standard form, but it can be translated into standard form essentially by choosing a basis for the null space \\\\(W\\\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks about [linear programming](https://en.wikipedia.org/wiki/Linear_programming)\n",
    "\n",
    "### History\n",
    "\n",
    "The idea arose during World War II to reduce costs for the military. It was first developed in 1939 by [Leonid Kantorovich](https://en.wikipedia.org/wiki/Leonid_Kantorovich), a Russian mathematician and economist. \n",
    "In the 1970s, he won the Nobel Prize in Economics for his “contributions to the theory of optimum allocation of resources.”\n",
    "\n",
    "For more information, see this [historical discussion](https://en.wikipedia.org/wiki/Linear_programming#History). Significant contributions include\n",
    "the [simplex method](https://en.wikipedia.org/wiki/Simplex_algorithm), invented by George Dantzig in the late 1940s.\n",
    "\n",
    "\n",
    "### Applications\n",
    "\n",
    "\n",
    "Linear programming problems arise naturally in many settings:\n",
    "- minimal staffing needed to complete scheduled tasks\n",
    "- maximizing profit & minimizing costs when considering multiple options\n",
    "- minimizing risk of investment subject to achieving a return\n",
    "- minimizing transport costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `scipy` to solve linear programs\n",
    "\n",
    "The `scipy` library (more precisely, the `scipy.optimize` library) provides a `python` function which implements various algorithms for solving linear programs.\n",
    "\n",
    "The `API` interface of this function can be found here:\n",
    "\n",
    "[docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html)\n",
    "\n",
    "Here is a minimalist sketch.\n",
    "\n",
    "The function call\n",
    "```\n",
    "linprog(c,A_ub=A,b_ub=b,bounds)\n",
    "```\n",
    "for a 1 dimensional \"row vector\" c of dimension \\\\(n\\\\)\n",
    "*minimizes* the linear objective function\n",
    "\\\\[\\mathbf{x} \\mapsto \\mathbf{c}\\cdot \\mathbf{x}\\\\]\n",
    "subject to constraint\n",
    "\\\\[A \\cdot \\mathbf{x} \\le \\mathbf{b}\\\\]\n",
    "determined by the \\\\(r \\times n\\\\) matrix \\\\(A\\\\)\n",
    "and the vector \\\\(\\mathbf{b} \\in \\mathbf{R}^n\\\\),\n",
    "and subject to the additional constraints \n",
    "\\\\[\\mathbf{lb} \\le \\mathbf{x} \\le \\mathbf{ub}\\\\]\n",
    "where the vectors \\\\(\\mathbf{lb},\\mathbf{ub}\\\\) are determined\n",
    "by the argument `bounds`.\n",
    "\n",
    "`bounds` may be omitted, and in that case, \\\\(\\mathbf{lb} = \\mathbf{0}\\\\),\n",
    "and \\\\(\\mathbf{ub}\\\\) is the value `None`, which means that no upper bound is required on \\\\(\\mathbf{x}\\\\).\n",
    "\n",
    "### Remarks:\n",
    "\n",
    "* Note that use of the argument `bounds` asks `linprog` to solve linear programs that aren't in standard form. The \"default\" value of `bounds` could have been achieved by adding extra rows to \\\\(A\\\\); indeed, consider the \\\\((r+n) \\times 2n\\\\) matrix\n",
    "\\\\[\\widetilde{A} = \\begin{pmatrix} A & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & -I_n\n",
    "\\end{pmatrix}\\\\]\n",
    "and the vector\n",
    "\\\\[\\widetilde{\\mathbf{b}} = \\begin{bmatrix} \\mathbf{b} \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\in \\mathbf{R}^{r+n};\\\\]\n",
    "the inequality constraint\n",
    "\\\\[\\widetilde{A} \\cdot \\mathbf{x} \\le \\widetilde{\\mathbf{b}}\\\\]\n",
    "is equivalent to the pair of contraints\n",
    "\\\\[A \\cdot \\mathbf{x} \\le \\mathbf{b}, \\quad \\mathbf{0} \\le \\mathbf{x}\\\\].\n",
    "\n",
    "* the `linprog` function has other optional arguments.\n",
    "For example, we can call\n",
    "```\n",
    "linprog(c,A_ub=A,b_ub=b,method)\n",
    "```\n",
    "where the optional argumnet\n",
    "`method` can be one of the strings ‘interior-point’, ‘revised-simplex’, ‘simplex’;\n",
    "this will determine which algorithm will be used. We are going to sketch a description of the algorithm simplex method later. By default, `linprog` uses the 'interior-point' algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "Let's first check the `linprog` function on our *carpenter* example.\n",
    "Notice that `linprog` only *minimizes* its objective function. Note that maximizing the linear objective function determined by the row vector \\\\(\\mathbf{c} \\in \\mathbf{R}^{1 \\times r}\\\\) is the same as minimizing the linear objective function determined\n",
    "by \\\\(-\\mathbf{c}\\\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "c = [-25,-30]\n",
    "A = [[5,4],[20,30]]\n",
    "b = [120,690]\n",
    "\n",
    "res=linprog(c,A_ub=A,b_ub=b)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
